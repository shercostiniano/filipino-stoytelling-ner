{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('talon', 'VBAF'), ('unggoy', 'NNC'), ('puno', 'VBW')]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from data_utils import sentence_to_list_without_stopwords\n",
    "\n",
    "input = 'tumalon ang unggoy sa mapuno'\n",
    "input = ' '.join(sentence_to_list_without_stopwords(input))\n",
    "\n",
    "p1 = subprocess.run(['java', '-jar', '--enable-preview', 'fspost-lemma.jar', input], capture_output=True, text=True)\n",
    "output = p1.stdout.split('\\n')[3:-1]\n",
    "tag = output[0].split()\n",
    "word = output[1].split()\n",
    "[[(word,tag) for word,tag in zip(word,tag)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure to finish the steps in 04-EDA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>taba</td>\n",
       "      <td>Perception_Feel_Emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>taboy</td>\n",
       "      <td>Communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>taboy</td>\n",
       "      <td>Contact_Interact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tag</td>\n",
       "      <td>Objects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taga</td>\n",
       "      <td>Humans_Body</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tokens                     tags\n",
       "0   taba  Perception_Feel_Emotion\n",
       "1  taboy            Communication\n",
       "2  taboy         Contact_Interact\n",
       "3    tag                  Objects\n",
       "4   taga              Humans_Body"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_semantics_predefined = pd.read_csv(r'dataset\\doccano-annotated\\complete-unique-label-eda-collapsed.csv')\n",
    "df_semantics_predefined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting POS Tag to Semantics Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb = ['Motion','Change','Contact','Communication','Perception_Feel_Emotion']\n",
    "test = \"Contact_Interact\"\n",
    "any([v for v in verb if v in test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['alitaptap', 'alitaptap', 'halina', 'halina',...</td>\n",
       "      <td>['FW', 'FW', 'FW', 'FW', 'DTCP', 'NNC_CCP', 'V...</td>\n",
       "      <td>[Animals, Animals, O, O, O, O, O, O, O, Natura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['alitaptap', 'alitaptap', 'halina', 'halina',...</td>\n",
       "      <td>['FW', 'FW', 'FW', 'FW', 'RBW', 'VBTF']</td>\n",
       "      <td>[Animals, Animals, O, O, Natural_Environment, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['darating', 'umaga']</td>\n",
       "      <td>['VBTF', 'RBW']</td>\n",
       "      <td>[O, Natural_Environment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['halina', 'huwag', 'takot', 'dilim', 'alitapt...</td>\n",
       "      <td>['RBW', 'RBF', 'VBW', 'NNC', 'NNC', 'NNC', 'NN...</td>\n",
       "      <td>[O, O, O, Natural_Environment, Animals, Animal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['halina', 'aliw']</td>\n",
       "      <td>['RBW', 'NNC']</td>\n",
       "      <td>[O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  ['alitaptap', 'alitaptap', 'halina', 'halina',...   \n",
       "1  ['alitaptap', 'alitaptap', 'halina', 'halina',...   \n",
       "2                              ['darating', 'umaga']   \n",
       "3  ['halina', 'huwag', 'takot', 'dilim', 'alitapt...   \n",
       "4                                 ['halina', 'aliw']   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['FW', 'FW', 'FW', 'FW', 'DTCP', 'NNC_CCP', 'V...   \n",
       "1            ['FW', 'FW', 'FW', 'FW', 'RBW', 'VBTF']   \n",
       "2                                    ['VBTF', 'RBW']   \n",
       "3  ['RBW', 'RBF', 'VBW', 'NNC', 'NNC', 'NNC', 'NN...   \n",
       "4                                     ['RBW', 'NNC']   \n",
       "\n",
       "                                            ner_tags  \n",
       "0  [Animals, Animals, O, O, O, O, O, O, O, Natura...  \n",
       "1   [Animals, Animals, O, O, Natural_Environment, O]  \n",
       "2                           [O, Natural_Environment]  \n",
       "3  [O, O, O, Natural_Environment, Animals, Animal...  \n",
       "4                                             [O, O]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "\n",
    "verb = ['Motion','Change','Contact','Communication','Perception_Feel_Emotion']\n",
    "sentence_semantics = []\n",
    "df_semantics = pd.read_csv(r'dataset\\annotation\\tl-storytelling-pos-tagged-lemmatized.csv')\n",
    "for tokens,tags in zip(df_semantics['tokens'],df_semantics['tags']):\n",
    "    semantic_tags = []\n",
    "    for token,tag in zip(literal_eval(tokens),literal_eval(tags)):\n",
    "        index = df_semantics_predefined[df_semantics_predefined['tokens'] == token].index.values\n",
    "        detected_values = df_semantics_predefined.loc[index]['tags'].values\n",
    "        if len(detected_values): \n",
    "            if any([v for v in verb if v in detected_values[0]]):\n",
    "                semantic_tags.append(\"O\")\n",
    "\n",
    "            # if len(detected_values) > 1:\n",
    "            #     if 'VB' in tag:\n",
    "            #         # verb_semantic = [x for x in detected_values if x in verb]\n",
    "            #         semantic_tags.append(verb_semantic)\n",
    "            else:\n",
    "                semantic_tags.append(detected_values[0])\n",
    "        else:\n",
    "            semantic_tags.append(\"O\")\n",
    "    sentence_semantics.append(semantic_tags)\n",
    "df_semantics['ner_tags'] = sentence_semantics\n",
    "df_semantics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['kaniya', 'sangag', 'sarap']</td>\n",
       "      <td>['PRSP_CCP', 'VBTS', 'JJD']</td>\n",
       "      <td>['O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['balik', 'srey', 'pov', 'kaniya', 'nayon', 'b...</td>\n",
       "      <td>['VBAF', 'FW', 'FW', 'PRSP_CCP', 'NNC', 'VBTS'...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'Urban_Environment', 'O',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['kukunin', 'rin', 'saya', 'puchku']</td>\n",
       "      <td>['VBTF_VBOF', 'RBI', 'JJD_CCP', 'NNC']</td>\n",
       "      <td>['O', 'O', 'Objects', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['rona', 'halika', 'yaya', 'tatay']</td>\n",
       "      <td>['FW', 'NNC', 'NNC', 'NNC']</td>\n",
       "      <td>['O', 'O', 'Humans_Body', 'Humans_Body']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['pasok', 'tubig', 'bangka', 'kongkea']</td>\n",
       "      <td>['VBAF', 'NNC', 'NNC', 'NNC']</td>\n",
       "      <td>['O', 'Natural_Environment', 'Transportation',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0                      ['kaniya', 'sangag', 'sarap']   \n",
       "1  ['balik', 'srey', 'pov', 'kaniya', 'nayon', 'b...   \n",
       "2               ['kukunin', 'rin', 'saya', 'puchku']   \n",
       "3                ['rona', 'halika', 'yaya', 'tatay']   \n",
       "4            ['pasok', 'tubig', 'bangka', 'kongkea']   \n",
       "\n",
       "                                                tags  \\\n",
       "0                        ['PRSP_CCP', 'VBTS', 'JJD']   \n",
       "1  ['VBAF', 'FW', 'FW', 'PRSP_CCP', 'NNC', 'VBTS'...   \n",
       "2             ['VBTF_VBOF', 'RBI', 'JJD_CCP', 'NNC']   \n",
       "3                        ['FW', 'NNC', 'NNC', 'NNC']   \n",
       "4                      ['VBAF', 'NNC', 'NNC', 'NNC']   \n",
       "\n",
       "                                            ner_tags  \n",
       "0                                    ['O', 'O', 'O']  \n",
       "1  ['O', 'O', 'O', 'O', 'Urban_Environment', 'O',...  \n",
       "2                         ['O', 'O', 'Objects', 'O']  \n",
       "3           ['O', 'O', 'Humans_Body', 'Humans_Body']  \n",
       "4  ['O', 'Natural_Environment', 'Transportation',...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('huggingface-autotrain-dataset-batch1.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['kaniya', 'sangag', 'sarap']</td>\n",
       "      <td>['PRSP_CCP', 'VBTS', 'JJD']</td>\n",
       "      <td>['O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['balik', 'srey', 'pov', 'kaniya', 'nayon', 'b...</td>\n",
       "      <td>['VBAF', 'FW', 'FW', 'PRSP_CCP', 'NNC', 'VBTS'...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'Urban_Environment', 'O',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['kukunin', 'rin', 'saya', 'puchku']</td>\n",
       "      <td>['VBTF_VBOF', 'RBI', 'JJD_CCP', 'NNC']</td>\n",
       "      <td>['O', 'O', 'Objects', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['rona', 'halika', 'yaya', 'tatay']</td>\n",
       "      <td>['FW', 'NNC', 'NNC', 'NNC']</td>\n",
       "      <td>['O', 'O', 'Humans_Body', 'Humans_Body']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['pasok', 'tubig', 'bangka', 'kongkea']</td>\n",
       "      <td>['VBAF', 'NNC', 'NNC', 'NNC']</td>\n",
       "      <td>['O', 'Natural_Environment', 'Transportation',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>['nang', 'uwi', 'iyak']</td>\n",
       "      <td>['RBW', 'VBAF', 'VBTR_VBAF']</td>\n",
       "      <td>['O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>['aalis', 'ba', 'mamaya', 'aalis', 'ba', 'ngay...</td>\n",
       "      <td>['VBTF', 'RBI', 'RBW', 'VBTF', 'RBI', 'RBW_CCP...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'Natural_Enviro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>['nakiusap', 'doktor', 'kay', 'ira', 'turok', ...</td>\n",
       "      <td>['VBTS', 'NNC', 'DTP', 'FW', 'VBAF', 'DTP', 'N...</td>\n",
       "      <td>['O', 'Humans_Body', 'O', 'O', 'O', 'O', 'Anim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>['baba', 'tatay', 'kay', 'rona']</td>\n",
       "      <td>['VBAF', 'NNC', 'DTP', 'NNC']</td>\n",
       "      <td>['O', 'Humans_Body', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>['dati', 'tatlo', 'isda', 'laki', 'isda']</td>\n",
       "      <td>['VBAF', 'JJN_CCP', 'NNC', 'JJCS_JJD_CCP', 'NNC']</td>\n",
       "      <td>['O', 'O', 'Animals', 'O', 'Animals']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "0                         ['kaniya', 'sangag', 'sarap']   \n",
       "1     ['balik', 'srey', 'pov', 'kaniya', 'nayon', 'b...   \n",
       "2                  ['kukunin', 'rin', 'saya', 'puchku']   \n",
       "3                   ['rona', 'halika', 'yaya', 'tatay']   \n",
       "4               ['pasok', 'tubig', 'bangka', 'kongkea']   \n",
       "...                                                 ...   \n",
       "2995                            ['nang', 'uwi', 'iyak']   \n",
       "2996  ['aalis', 'ba', 'mamaya', 'aalis', 'ba', 'ngay...   \n",
       "2997  ['nakiusap', 'doktor', 'kay', 'ira', 'turok', ...   \n",
       "2998                   ['baba', 'tatay', 'kay', 'rona']   \n",
       "2999          ['dati', 'tatlo', 'isda', 'laki', 'isda']   \n",
       "\n",
       "                                                   tags  \\\n",
       "0                           ['PRSP_CCP', 'VBTS', 'JJD']   \n",
       "1     ['VBAF', 'FW', 'FW', 'PRSP_CCP', 'NNC', 'VBTS'...   \n",
       "2                ['VBTF_VBOF', 'RBI', 'JJD_CCP', 'NNC']   \n",
       "3                           ['FW', 'NNC', 'NNC', 'NNC']   \n",
       "4                         ['VBAF', 'NNC', 'NNC', 'NNC']   \n",
       "...                                                 ...   \n",
       "2995                       ['RBW', 'VBAF', 'VBTR_VBAF']   \n",
       "2996  ['VBTF', 'RBI', 'RBW', 'VBTF', 'RBI', 'RBW_CCP...   \n",
       "2997  ['VBTS', 'NNC', 'DTP', 'FW', 'VBAF', 'DTP', 'N...   \n",
       "2998                      ['VBAF', 'NNC', 'DTP', 'NNC']   \n",
       "2999  ['VBAF', 'JJN_CCP', 'NNC', 'JJCS_JJD_CCP', 'NNC']   \n",
       "\n",
       "                                               ner_tags  \n",
       "0                                       ['O', 'O', 'O']  \n",
       "1     ['O', 'O', 'O', 'O', 'Urban_Environment', 'O',...  \n",
       "2                            ['O', 'O', 'Objects', 'O']  \n",
       "3              ['O', 'O', 'Humans_Body', 'Humans_Body']  \n",
       "4     ['O', 'Natural_Environment', 'Transportation',...  \n",
       "...                                                 ...  \n",
       "2995                                    ['O', 'O', 'O']  \n",
       "2996  ['O', 'O', 'O', 'O', 'O', 'O', 'Natural_Enviro...  \n",
       "2997  ['O', 'Humans_Body', 'O', 'O', 'O', 'O', 'Anim...  \n",
       "2998                     ['O', 'Humans_Body', 'O', 'O']  \n",
       "2999              ['O', 'O', 'Animals', 'O', 'Animals']  \n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[:3000]\n",
    "df_test = df[3000:]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('huggingface-autotrain-dataset-train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-defining dataset with labeled unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval \n",
    "\n",
    "# create an empty list to create a list of dictionaries\n",
    "list_json = []\n",
    "\n",
    "for x, i in enumerate(sentences):\n",
    "    i = literal_eval(i) #Parsing string array to array\n",
    "    list_json.append({\"id\": x}) # create id key for sentence\n",
    "    list_json[x][\"text\"] = ' '.join(i) # create the text key for the sentence\n",
    "    list_json[x][\"label\"] = [] # create an empty label key to later append\n",
    "    for y, j in enumerate(labels[x]):\n",
    "        if j in unique_labels:\n",
    "            word = i[y] # determine what the word is\n",
    "            # \n",
    "            # If I don't add an if statement here, the label indexes for the first always got tagged 1 index to the right\n",
    "            # I am not sure why but this if statement fixes the problem\n",
    "            #\n",
    "            if y == 0: \n",
    "                # determining the start and end index of the label in the sentence\n",
    "                wordStartIndex1 = len(\" \".join(i[0:y])) # join word elements with a space until the word index to determine the start of the label index\n",
    "                wordEndIndex1 = len(\" \".join(i[0:y]))+ len(word) # add the length of the word to determine the End index\n",
    "                list_json[x][\"label\"].append([wordStartIndex1, wordEndIndex1, j])\n",
    "            # same thing but if its not the first of the sentence, we add 1 to the start and end indexes\n",
    "            else:\n",
    "                wordStartIndex1 = len(\" \".join(i[0:y]))+1\n",
    "                wordEndIndex1 = len(\" \".join(i[0:y]))+ len(word)+1\n",
    "                list_json[x][\"label\"].append([wordStartIndex1, wordEndIndex1, j])\n",
    "list_json[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can just dump a list of dictionaries as a json1 file\n",
    "# which is the format required by doccano\n",
    "import json\n",
    "with open('predefined-dataset-batch1.json1', 'w') as f:\n",
    "    for d in list_json:\n",
    "        json.dump(d, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env_mgnntagset')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "218f7a967afb662943e57b2677ccb949839c78ab897dd43b6bac4d0b3635545d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
